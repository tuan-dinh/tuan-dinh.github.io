---
layout: post
title:  "Utilizing Language-Image Pretraining for Efficient and Robust Bilingual Word Alignment"
date:   2022-10-05 22:20:59 +00:00
image: /images/codedinvnet.png
categories: ml
venue: "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP Findings)"
arxiv: "https://arxiv.org/abs/2205.11616"
code: "https://github.com/UW-Madison-Lee-Lab/walip"
summary: "We study the problem of unsupervised bilingual work alignment. Our idea is to utilize the text-image correlation with the CLIP-based embedding to match pairs of words in the unsupervised manner. Our method, WALIP, uses these pivot pairs to learn the linear mapping between two words' static embedding sets via our robust matching algorithm. We show that our method works comparably well and more robust against the language dissimilarity."
badge: "EMNLP"
authors: "<ins><strong>Tuan Dinh</strong></ins>, Jy-yong Sohn, Shashank Rajput, Timothy Ossowski, Yifei Ming, Junjie Hu, Dimitris Papailiopoulos, Kangwook Lee"
---
<!-- [Presented Slides](){:target="_blank"} -->
